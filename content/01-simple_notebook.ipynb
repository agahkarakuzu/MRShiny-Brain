{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "build = 'archive' # 'archive' uses the neurolibre archive of the data., 'latest' would download the latest versions of the data."
   ]
  },
  {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
  "<p>\n",
  "<center>\n",
  "<b>\n",
  "<h3>\n",
  "Integrating Structural, Functional, and Biochemical Brain Imaging Data with MRShiny Brain - An Interactive Web Application\n",
  "</h3>\n",
  "\n",
  "<p>\n",
  "</sup>Jessica Archibald<sup>1, 2</sup>, Alexander Mark Weber<sup>3, 4</sup>, Paulina Scheuren<sup>1, 9</sup>, Oscar Ortiz<sup>1</sup>, Cassandra Choles<sup>1, 9</sup>, Jaime Lee<sup>1, 9</sup>, Niklaus Zölch<sup>5</sup>, Erin L. MacMillan<sup>6, 8, 7</sup>, John L.K Kramer<sup>1, 2, 9</sup>\n",
  "</p>\n",
  "</b>\n",
  "\n",
  "<ul style=\"list-style-type: none\">\n",
  "<li><sup>*</sup>Authors ELM and JLKK contributed equally to this work</li>\n",
  "</ul>\n",
  "</center>\n",
  "\n",
  "<p style=\"text-align:justify;font-size:70%\">\n",
  "<sup>1</sup>International Collaboration on Repair Discoveries (ICORD), University of British Columbia, Vancouver, Canada.\n",
  "<sup>2</sup>Department of Experimental Medicine, University of British Columbia, Vancouver, Canada.\n",
  "<sup>3</sup>Department of Pediatrics, University of British Columbia, Vancouver, Canada.\n",
  "<sup>4</sup>BC Children Hospital Research Institute, Vancouver, Canada.\n",
  "<sup>5</sup>Forensic Medicine, Universität Zürich, Zürich, Switzerland.\n",
  "<sup>6</sup>Department of Radiology, University of British Columbia, Vancouver, Canada.\n",
  "<sup>7</sup>Image Tech Lab, Simon Fraser University, Surrey, Canada.\n",
  "<sup>8</sup>Philips Healthcare Canada, Markham, Canada.\n",
  "<sup>9</sup>Department of Anesthesiology, Pharmacology and Therapeutics, Faculty of Medicine, University of British Columbia, Vancouver, Canada.\n",
  "</p>\n",
  "\n",
  "</p>"
 ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "# Abstract\n",
    "\n",
    "The utilization of structural, functional, and biochemical data from the human brain has grown in addressing inquiries related to neurodegenerative and neuropsychiatric conditions. However, the normal variability within these measures has not been systematically reported.\n",
    "\n",
    "In this work, a database comprising these outcome measures in a healthy population (n=51) was established to potentially serve as a comparative reference. Healthy individuals underwent standardized procedures to ensure consistent collection of magnetic resonance imaging (MRI) and spectroscopy data.\n",
    "\n",
    "The MRI data was acquired using a 3T scanner with various sequences, including MPRAGE 3D T1w, pseudo-continuous arterial spin labelling (pCASL), and single voxel proton magnetic resonance spectroscopy (1H-MRS). Established and custom software tools were employed to analyze outcome measures such as tissue segmentation, cortical thickness, cerebral blood flow, and metabolite levels measured by MRS.\n",
    "\n",
    "This study provides a comprehensive overview of the data analysis process, aiming to facilitate future utilization of the collected data."
  ]
},
{
 "cell_type": "markdown",
 "metadata": {},
 "source": [
  "<h2 style=\"display:inline\"><center> MRShiny Brain </center></h2>\n",
  "<iframe src=\"https://mrshiny-brain.shinyapps.io/MRshinybrain/\" width=\"120%\" height=\"750px\" style=\"border:none;margin: 0 -10%\"></iframe>\n",
  "<p></p>"
 ]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
  "# 1 &nbsp; &nbsp; | &nbsp; &nbsp; INTRODUCTION\n",
  "\n",
  "The pursuit to understand the biological foundations of neurodegenerative conditions has led to an extensive exploration of brain imaging data. Integrating various forms of brain imaging data and neurophysiological techniques such as magnetic resonance spectroscopy (MRS) has emerged as an essential approach to obtain a comprehensive understanding of these intricate conditions. By combining morphological, functional, and biochemical data, researchers gain invaluable insights into the intricate mechanisms underlying neurodegenerative diseases. These insights extend to identifying potential biomarkers and therapeutic targets, thereby paving the way for improved treatment strategies.\n",
  "\n",
  "A notable challenge in understanding the brain’s behaviour in disease lies in the incomplete comprehension of its state within a healthy population at rest. In the field of brain imaging, the importance of considering variability between individuals and across different brain regions is high. Creating a comprehensive database that includes data from multiple brain regions, and multiple modalities in a healthy population is invaluable for guiding future research and clinical use. This database acts as an important reference point, allowing researchers to measure deviations from the average, enabling early disease detection and monitoring progression across diverse populations. Furthermore, it enables a focused analysis of specific subsets of groups, for example, examining outcomes-based factors like sex or age that allow for matched comparisons.\n",
  "\n",
  "Our study provides a description of the meticulous methodology that ensures consistency the data acquisition and analysis. Standardized procedures have been followed to guarantee the accuracy and reliability of the data gathered. This multi-modal approach encompasses a range of outcomes, including morphological measures such as brain tissue volume (gray matter, white matter, and cerebral spinal fluid) and cortical thickness. Additionally, we have included blood perfusion levels, biochemical profiles of different brain regions assessed through MRS, and temperature via MRS thermometry.\n",
  "\n",
  "The MRShiny Brain application has been developed as a normative live database, designed to facilitate user-friendly access to a wide spectrum of morphological, perfusion, and biochemical brain data. Our core objective revolves around presenting a normative representation of the healthy brain during rest with the intent of empowering the scientific community to formulate a priori hypotheses. Recognizing that the analysis of MRI/MRS data can be a time-consuming and expertise-demanding task, we aim to provide this data in an accessible format, offering an informative overview of key measures for those seeking valuable insights.\n",
  "\n",
  "As we examine the complex interplay brain function, it becomes evident that understanding the brain in a healthy state is pivotal to understanding it in pathological states. The challenge of understanding the brain's intricacies in various states, particularly during rest, underscores the importance of our study. By building a comprehensive foundation of knowledge through the integration of diverse imaging data, into a user-friendly database we aspire to drive advancements in our understanding of neurodegenerative conditions, leading to enhanced diagnostic precision and targeted therapeutic interventions."
]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "# 2 &nbsp; &nbsp; | &nbsp; &nbsp; METHODS\n",
    "\n",
    "## 2.1 &nbsp; &nbsp; | &nbsp; &nbsp; Demographics\n",
    "This is a live database that undergoes continuous updates, resulting in changes to the following information. At the time of this report, 51 healthy participants have been recruited for this experiment (24M, mean age = 27.4 years, SD = 6.16 years, range = 19 - 47 years). Participants were asked to arrive at the laboratory in a fasting state to account for food intake effects[@kubota2021dynamic]. The timing of the scan was kept consistent (11:30 am-12:30 pm) across participants, in order to account for circadian rhythm effects of metabolites[@eckelmahan2013metabolism]. Regarding female participants, their testing was based on self-reported information regarding the phase of their menstrual cycle, specifically targeting the follicular phase[@hjelmervik2018sex]. Figure 1 illustrates the study design.\n",
    "\n",
    "## 2.2 &nbsp; &nbsp; | &nbsp; &nbsp; MR Acquisition Protocol\n",
    "MRI data were collected using a 3T Philips Ingenia Elition X with a 32-channel SENSE head coil, and the sequences included:\n",
    "1. A MPRAGE 3D T1 weighted scan (TE/TR/TI=4.3/9.3/950ms, shot interval=2400ms, +0.8mm³ isotropic resolution, FOV (ap/rl/fh)=256/256/180mm³, scan time=5:49).\n",
    "2. A pseudo-continuous arterial spin labelling (pCASL) sequence was used to assess CBF. The sequence consisted of four pairs of perfusion-weighted and control scans (TE/TR=12/4174ms, post-labelling duration=2000ms, labelling duration=1800, total scan duration=5.59 min).\n",
    "3. Cingulate Cortex single voxel 1H-MRS scans (sLASER, TE/TR=32/5000ms, NSA=64, voxel size=24/22/15mm³ =7.9mL, automated 2nd order shimming, 32-step phase cycle, water suppression using the frequency selective Excitation option). The order of the four cingulate cortex voxels was randomized for each participant, including the periungual anterior cingulate cortex (pACC), the anterior and posterior mid-cingulate cortex (aMCC, pMCC) and the posterior cingulate cortex (PCC)[@vogt2019cingulate].\n",
    "\n",
    "## 2.3 &nbsp; &nbsp; | &nbsp; &nbsp; MR Analysis\n",
    "**Structural Measures:** Image Segmentation was performed in FSL (v 6.05) using default options, ROI segmentation was performed using in-house MATLAB scripts. ROI Cortical Thickness was performed in native space for each subject using Freesurfer (v 7.2.0) [Code Availability ](https://github.com/arcj-hub/Freesurfer-CT-native-space).\n",
    "**Arterial Spin-Labeled MRI Preprocessing and Cerebral Blood Flow Computation:**\n",
    "Arterial spin-labeled MRI images were preprocessed using ASLPrep 0.6.0rc[debimpe2022aslprep;salo2023aslprep], which is based on fMRIPrep[@esteban2019fmriprep;@esteban2020analysis] and Nipype 1.8.6s.\n",
    "_Anatomical data preprocessing_\n",
    "A total of 50 T1-weighted (T1w) images were found within the input BIDS dataset. The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU) with `N4BiasFieldCorrection`[@avants2014ants], distributed with ANTs 2.3.3[@avants2008symmetric;hang2001segmentation], and used as T1w-reference throughout the workflow. The T1w-reference was then skull-stripped with a Nipype implementation of the `antsBrainExtraction.sh` workflow (from ANTs), using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain extracted T1w using `fast` [FSL 6.0.7.1][@jenkinson2002improved].\n",
    "_ASL data preprocessing_\n",
    "For the 1 ASL run found per subject, the following preprocessing was performed.\n",
    "First, the middle volume of the ASL timeseries was selected as the reference volume and brain extracted using Nipype's custom brain extraction workflow. First, the middle M0 volume of the ASL timeseries was selected as the reference volume and brain extracted using Nipype’s custom brain extraction workflow. Susceptibility distortion correction (SDC) was omitted. Head-motion parameters were estimated for the ASL data using FSL's `mcflirt`[@wang2008empirical]. Motion correction was performed separately for each of the volume types in order to account for intensity differences between different contrasts, which, when motion corrected together, can conflate intensity differences with head motions[@jenkinson2001global]. Next, ASLPrep concatenated the motion parameters across volume types and re-calculated relative root mean-squared deviation. ASLPrep co-registered the ASL reference to the T1w reference using FSL’s `flirt`[@greve2009accurate], which implemented the boundary-based registration cost-function[@power2014methods]. Co-registration used 6 degrees of freedom. The quality of co-registration and normalization to template was quantified using the Dice and Jaccard indices, the cross-correlation with the reference image, and the overlap between the ASL and reference images (e.g., image coverage). Several confounding timeseries were calculated, including both framewise displacement (FD) and DVARS. FD and DVARS are calculated using the implementations in Nipype (following the definition by[@buxton1998general]) for each ASL run. ASLPrep summarizes in-scanner motion as the mean framewise displacement and relative root-mean square displacement.\n",
    "_Cerebral blood flow computation and denoising_\n",
    "ASLPrep calculated cerebral blood flow (CBF) from the single-delayPCASL using a single-compartment general kinetic model[@abraham2014machine]. Calibration (M0) volumes associated with the ASL scan were smoothed with a Gaussian kernel (FWHM=5 mm) and the average calibration image was calculated and scaled by 1. First, the middle volume of the ASL timeseries was selected as the reference volume and brain extracted using Nipype's custom brain extraction workflow.\n",
    "_ROI CBF estimates_\n",
    "ROI perfusion levels were extracted in native space using each ROI’s mask. Firstly the images were co-registered using ‘flirt’[@greve2009accurate], the resampled mask was then binarized, and ROI CBF was calculated using fslstats `cbf_extraction.sh` [Code Availability ](https://github.com/arcj-hub/ASLprep-CBF-Analysis).\n",
    "_Quality Evaluation Index (QEI)_\n",
    "The QEI was computed for each CBF map [@dolui2017structural]. QEI is based on the similarity between the CBF and the structural images, the spatial variability of the CBF image, and the percentage of grey matter voxels containing negative CBF values ‘Quality_aslprep.sh`  [Code Availability ](https://github.com/arcj-hub/ASLprep-CBF-Analysis). For more details of the pipeline, see [ASLPrep-Documentation].\n",
    "**MR Spectroscopy:** MRS analysis was performed following the recent expert guideline recommendations22–24. MRS data was pre-processed (e.g., frequency alignment, and eddy-current correction) and quantified using in-house MATLAB scripts. Spectral fitting was performed in LCModel (6.3). The basis set was simulated using he FID-A run-simLaserShapted_fast.m[@simpson2017advanced] function- (Link code-). The simulation included the following metabolites: PE, Asc, Scyllo, Glu, Gln, Cre, NAA, NAAG, PCr, GSH, Gly, Glc, GPC, Ala, Asp, GABA, Ins, Lac, and Tau. The LCModel fit was performed in the range of 0.5 to 4.0 ppm."
  ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "## 2.4 &nbsp; &nbsp; | &nbsp; &nbsp; Dashboard\n",
    "To facilitate the reuse and exploration of the data, we have developed an interactive web application using R Shiny. This application provides an intuitive and user-friendly interface for accessing and analyzing the dataset. The application allows users to interact with the data in a dynamic manner, enabling exploration, visualization, and integration with other datasets. The dataset is composed of different types of data structural, perfusion, and biochemical. These data can all be downloaded directly via the MRShiny Brain web-application.\n",
    "\n",
    "**Structural**\n",
    "1. GM: gray matter fraction in each region of interest.\n",
    "2. WM: white matter fraction in each region of interest.\n",
    "3. CSF: cerebrospinal fluid fraction in each region of interest.\n",
    "4. CT: Cortical thickness in mm in each region of interest.\n",
    "\n",
    "**Perfusion**\n",
    "1. CBF: cerebral blood flow (mL/gr/min) in each region of interest.\n",
    "\n",
    "**Biochemical**\n",
    "1. Metabolites available: N-Acetyl aspartic acid (NAA), total creatine (tCr), total choline (tCho), myoinositol (mI), glutamate (Glu), glutamine (Gln), and glutamate+glutamine (Glx).\n",
    "2. Quality Measures signal-to-noise-ration (SNR), linewidth of the water spectrum (LW), and Cramer-Rao Lower Bounds of each metabolite (CRLB)."
  ]
},

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot of the T<sub>1</sub> data for all submissions and their ROIs is shown in Figure 4 (phantom a-c, and human brains d-f). The NIST phantom T<sub>1</sub> measurements are presented in each plot for different axes types (linear, log, and error) to better visualize the results. Figure 4-a shows good agreement for this dataset in comparison with the temperature-corrected reference T<sub>1</sub> values. However, this trend did not persist for low T<sub>1</sub> values (T<sub>1</sub> < 100-200 ms), as seen in the log-log plot (Figure 4-b), which was expected because the imaging protocol is optimized for human brain T<sub>1</sub> values (T<sub>1</sub> > 500 ms). Higher variability is seen at long T<sub>1</sub> values (T<sub>1</sub> ~ 2000 ms) in Figure 4-a. Errors exceeding 10% are observed in the phantom spheres with T1 values below 300 ms (Figure 4-c), and 3-4 measurements with outlier values exceeding 10% error were observed in the human brain tissue range (~500-2000 ms).\n",
    "\n",
    "Figure 4 d-f displays the scatter plot data for human datasets submitted to this challenge, showing mean and standard deviation T<sub>1</sub> values for the WM (genu and splenium) and GM (cerebral cortex and deep GM) ROIs. Mean WM T<sub>1</sub> values across all submissions were 828 ± 38 ms in the genu and 852 ± 49 ms in the splenium, and mean GM T<sub>1</sub> values were 1548 ± 156 ms in the cortex and 1188 ± 133 ms in the deep GM, with less variations overall in WM compared to GM, possibly due to better ROI placement and less partial voluming in WM. The lower standard deviations for the ROIs of human database ID site 9 (by submission 18, Figure 1, and seen in orange in Figure 4d-g) are due to good slice positioning, cutting through the AC-PC line and the genu for proper ROI placement, particularly for the corpus callosum and deep GM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output",
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# PYTHON CODE\n",
    "# Module imports\n",
    "\n",
    "# Base python\n",
    "import os\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import markdown\n",
    "import random\n",
    "\n",
    "# Graphical\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.colors\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display, HTML\n",
    "from plotly import __version__\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "config={\n",
    "    'showLink': False,\n",
    "    'displayModeBar': False,\n",
    "    'toImageButtonOptions': {\n",
    "                'format': 'png', # one of png, svg, jpeg, webp\n",
    "                'filename': 'custom_image',\n",
    "                'height': 300,\n",
    "                'width': 960,\n",
    "                'scale': 2 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "            }\n",
    "    }\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the color palette\n",
    "pal=sns.color_palette(\"Set2\")\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "import scipy.io\n",
    "\n",
    "# Data\n",
    "from repo2data.repo2data import Repo2Data\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "if build == 'latest':\n",
    "    if path.isdir('analysis')== False:\n",
    "        !git clone https://github.com/rrsg2020/analysis.git\n",
    "        dir_name = 'analysis'\n",
    "        analysis = os.listdir(dir_name)\n",
    "\n",
    "        for item in analysis:\n",
    "            if item.endswith(\".ipynb\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "            if item.endswith(\".md\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "elif build == 'archive':\n",
    "    if os.path.isdir(Path('../data')):\n",
    "        data_path = ['../data/rrsg-2020-note/rrsg-2020-neurolibre']\n",
    "    else:\n",
    "        # define data requirement path\n",
    "        data_req_path = os.path.join(\"..\", \"binder\", \"data_requirement.json\")\n",
    "        # download data\n",
    "        repo2data = Repo2Data(data_req_path)\n",
    "        data_path = repo2data.install()\n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from analysis.src.database import *\n",
    "from analysis.src.nist import get_reference_NIST_values, get_NIST_ids\n",
    "from analysis.src.tools import calc_error\n",
    "from analysis.src.nist import temperature_correction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('analysis/custom_matplotlibrc')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "fig_id = 0\n",
    "\n",
    "if build == 'latest':\n",
    "    database_path = Path('analysis/databases/3T_NIST_T1maps_database.pkl')\n",
    "    output_folder = Path(\"analysis/plots/03_singledataset_scatter_NIST-temperature-corrected/\")\n",
    "elif build=='archive':\n",
    "    database_path = Path(data_path[0] + '/analysis/databases/3T_NIST_T1maps_database.pkl')\n",
    "    output_folder = Path(data_path[0] + '/analysis/plots/03_singledataset_scatter_NIST-temperature-corrected/')\n",
    "\n",
    "estimate_type = 'mean' # median or mean\n",
    "\n",
    "## Define Functions\n",
    "def plot_single_scatter(x, y, y_std,\n",
    "                        title, x_label, y_label,\n",
    "                        file_prefix, folder_path, fig_id,\n",
    "                        y_type='linear'):\n",
    "    if y_type == 'linear':\n",
    "        plt.errorbar(x,y, y_std, fmt='o', solid_capstyle='projecting')\n",
    "        ax = plt.gca()\n",
    "        ax.axline((1, 1), slope=1, linestyle='dashed')\n",
    "        ax.set_ylim(ymin=0, ymax=2500)\n",
    "        ax.set_xlim(xmin=0, xmax=2500)\n",
    "    if y_type == 'log':\n",
    "        plt.loglog(x,y,'o')\n",
    "        ax = plt.gca()\n",
    "        ax.set_ylim(ymin=20, ymax=2500)\n",
    "        ax.set_xlim(xmin=20, xmax=2500)\n",
    "    if y_type == 'error_t1':\n",
    "        plt.errorbar(x,calc_error(x,y), fmt='o')\n",
    "        ax = plt.gca()\n",
    "        ax.axline((1, 0), slope=0, color='k')\n",
    "        ax.axline((1, -10), slope=0, linestyle='dashed', color='k')\n",
    "        ax.axline((1, 10), slope=0, linestyle='dashed', color='k')\n",
    "        ax.set_ylim(ymin=-100, ymax=100)\n",
    "        ax.set_xlim(xmin=0, xmax=2500)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if fig_id<10:\n",
    "        filename = \"0\" + str(fig_id) + \"_\" + file_prefix\n",
    "    else:\n",
    "        filename = str(fig_id) + \"_\" + file_prefix\n",
    "\n",
    "    fig.savefig(folder_path / (str(filename) + '.svg'), facecolor='white')\n",
    "    fig.savefig(folder_path / (str(filename) + '.png'), facecolor='white')\n",
    "    fig_id = fig_id + 1\n",
    "    plt.show()\n",
    "    return fig_id\n",
    "\n",
    "## Load database\n",
    "\n",
    "df = pd.read_pickle(database_path)\n",
    "\n",
    "\n",
    "## Initialize array\n",
    "\n",
    "dataset_mean = np.zeros((1,14))\n",
    "dataset_std = np.zeros((1,14))\n",
    "version = np.array([])\n",
    "temperature = np.array([])\n",
    "ref_values = np.zeros((1,14))\n",
    "\n",
    "intra_bool = np.array([])\n",
    "ii=0\n",
    "for index, row in df.iterrows():\n",
    "    intra_bool = np.append(intra_bool, round(index)==6)\n",
    "    if type(df.loc[index]['T1 - NIST sphere 1']) is np.ndarray:\n",
    "\n",
    "        version = np.append(version,df.loc[index]['phantom serial number'])\n",
    "        temperature = np.append(temperature, df.loc[index]['phantom temperature'])\n",
    "\n",
    "\n",
    "        if version[ii] == None:\n",
    "            version[ii] = 999 # Missing version, only known case is one where we have version > 42 right now.\n",
    "        \n",
    "        if temperature[ii] == None:\n",
    "            temperature[ii] = 20 # Missing temperature, assume it to be 20C (reference temperature).\n",
    "            \n",
    "            \n",
    "        if ii==0:\n",
    "            ref_values = get_reference_NIST_values(version[ii])\n",
    "            temp_corrected_ref_values = temperature_correction(temperature[ii], version[ii])\n",
    "        else:\n",
    "            ref_values = np.vstack((ref_values, get_reference_NIST_values(version[ii])))\n",
    "            temp_corrected_ref_values = np.vstack((temp_corrected_ref_values, temperature_correction(temperature[ii], version[ii])))\n",
    "        \n",
    "        tmp_dataset_estimate = np.array([])\n",
    "        tmp_dataset_std = np.array([])\n",
    "\n",
    "        for key in get_NIST_ids():\n",
    "            if estimate_type == 'mean':\n",
    "                tmp_dataset_estimate = np.append(tmp_dataset_estimate, np.mean(df.loc[index][key]))\n",
    "            elif estimate_type == 'median':\n",
    "                tmp_dataset_estimate = np.append(tmp_dataset_estimate, np.median(df.loc[index][key]))\n",
    "            else:\n",
    "                Exception('Unsupported dataset estimate type.')\n",
    "\n",
    "            tmp_dataset_std = np.append(tmp_dataset_std, np.std(df.loc[index][key]))\n",
    "\n",
    "        if ii==0:\n",
    "            dataset_estimate = tmp_dataset_estimate  \n",
    "            dataset_std = tmp_dataset_std\n",
    "        else:\n",
    "            dataset_estimate = np.vstack((dataset_estimate, tmp_dataset_estimate))\n",
    "            dataset_std = np.vstack((dataset_std, tmp_dataset_std))\n",
    "\n",
    "        ii=ii+1\n",
    "\n",
    "## Setup for plots\n",
    "fig_id = 0\n",
    "dims=ref_values.shape\n",
    "file_prefix = 'alldatasets'\n",
    "fig = make_subplots(rows=1, cols=3, horizontal_spacing = 0.08)\n",
    "\n",
    "data_lin_intra=[]\n",
    "data_lin_inter=[]\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgba(252, 141, 98, 0.5)'\n",
    "        marker_zorder=1\n",
    "    else:\n",
    "        marker_color='rgba(102, 194, 165, 0.5)'\n",
    "        marker_zorder=-1\n",
    "        \n",
    "    data_lin=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y=dataset_estimate[ii,:],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=dataset_std[ii,:],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    # For z-ordering   \n",
    "    if bool(intra_bool[ii]):\n",
    "        data_lin_intra.append(data_lin)\n",
    "    else:\n",
    "        data_lin_inter.append(data_lin)\n",
    "\n",
    "# For z-ordering   \n",
    "for trace in data_lin_inter:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=1\n",
    "    )\n",
    "for trace in data_lin_intra:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "data_log_intra=[]\n",
    "data_log_inter=[]\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgba(252, 141, 98, 0.5)'\n",
    "        marker_zorder=1\n",
    "    else:\n",
    "        marker_color='rgba(102, 194, 165, 0.5)'\n",
    "        marker_zorder=-1\n",
    "        \n",
    "    data_log=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y=dataset_estimate[ii,:],\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    # For z-ordering   \n",
    "    if bool(intra_bool[ii]):\n",
    "        data_log_intra.append(data_log)\n",
    "    else:\n",
    "        data_log_inter.append(data_log)\n",
    "\n",
    "# For z-ordering   \n",
    "for trace in data_log_inter:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "for trace in data_log_intra:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "data_error_intra=[]\n",
    "data_error_inter=[]\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgba(252, 141, 98, 0.5)'\n",
    "        marker_zorder=1\n",
    "    else:\n",
    "        marker_color='rgba(102, 194, 165, 0.5)'\n",
    "        marker_zorder=-1\n",
    "\n",
    "    data_error=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y= calc_error(temp_corrected_ref_values[ii,:],dataset_estimate[ii,:]),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # For z-ordering   \n",
    "    if bool(intra_bool[ii]):\n",
    "        data_error_intra.append(data_error)\n",
    "    else:\n",
    "        data_error_inter.append(data_error)\n",
    "\n",
    "# For z-ordering   \n",
    "for trace in data_error_inter:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=3\n",
    "    )\n",
    "for trace in data_error_intra:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='<b>Reference T<sub>1</sub> (ms)</b>',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title={\n",
    "        'text':'<b>T<sub>1</sub> estimate (ms)</b>',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title='<b>Reference T<sub>1</sub> (ms)</b>',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_yaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title={\n",
    "        'text':'<b>T<sub>1</sub> estimate (ms)</b>',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='<b>Reference T<sub>1</sub> (ms)</b>',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=3)\n",
    "\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[-100,100],\n",
    "    title={\n",
    "        'text':'<b>Error (%)</b>',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = -100,\n",
    "    dtick = 25,\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    title_font_size = 20,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=3,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=30, r=30, t=10, b=30),\n",
    "    paper_bgcolor='rgb(255, 255, 255)',\n",
    "    plot_bgcolor='rgb(255, 255, 255)',\n",
    "    legend_title=\"\",\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.05,\n",
    "            y=-0.22,\n",
    "            showarrow=False,\n",
    "            text='<b>a</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.3,\n",
    "            y=-0.22,\n",
    "            showarrow=False,\n",
    "            text='<b>b</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.68,\n",
    "            y=-0.22,\n",
    "            showarrow=False,\n",
    "            text='<b>c</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.99,\n",
    "            showarrow=False,\n",
    "            text='<b>Inter-sites</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20,\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            bgcolor='rgba(102, 194, 165, 0.8)'\n",
    "        ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.871,\n",
    "            showarrow=False,\n",
    "            text='<b>Intra-sites</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20,\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            bgcolor='rgba(252, 141, 98, 0.8)'\n",
    "        ),        \n",
    "    ]\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=300, width=960)\n",
    "\n",
    "#iplot(fig, filename = 'figure4a', config = config)\n",
    "plot(fig, filename = 'figure4a.html', config = config)\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "if build == 'latest':\n",
    "    if path.isdir('analysis')== False:\n",
    "        !git clone https://github.com/rrsg2020/analysis.git\n",
    "        dir_name = 'analysis'\n",
    "        analysis = os.listdir(dir_name)\n",
    "\n",
    "        for item in analysis:\n",
    "            if item.endswith(\".ipynb\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "            if item.endswith(\".md\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "elif build == 'archive':\n",
    "    if os.path.isdir(Path('../data')):\n",
    "        data_path = ['../data/rrsg-2020-note/rrsg-2020-neurolibre']\n",
    "    else:\n",
    "        # define data requirement path\n",
    "        data_req_path = os.path.join(\"..\", \"binder\", \"data_requirement.json\")\n",
    "        # download data\n",
    "        repo2data = Repo2Data(data_req_path)\n",
    "        data_path = repo2data.install()         \n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from analysis.src.database import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('analysis/custom_matplotlibrc')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "fig_id = 0\n",
    "\n",
    "# Configurations\n",
    "if build == 'latest':\n",
    "    database_path = Path('analysis/databases/3T_human_T1maps_database.pkl')\n",
    "    output_folder = Path(\"analysis/plots/08_wholedataset_scatter_Human/\")\n",
    "elif build=='archive':\n",
    "    database_path = Path(data_path[0] + '/analysis/databases/3T_human_T1maps_database.pkl')\n",
    "    output_folder = Path(data_path[0] + '/analysis/plots/08_wholedataset_scatter_Human/')\n",
    "\n",
    "estimate_type = 'mean' # median or mean\n",
    "\n",
    "# Load database\n",
    "\n",
    "df = pd.read_pickle(database_path)\n",
    "\n",
    "genu_estimate = np.array([])\n",
    "genu_std = np.array([])\n",
    "splenium_estimate = np.array([])\n",
    "splenium_std = np.array([])\n",
    "deepgm_estimate = np.array([])\n",
    "deepgm_std = np.array([])\n",
    "cgm_estimate = np.array([])\n",
    "cgm_std = np.array([])\n",
    "\n",
    "intra_bool = np.array([])\n",
    "ii = 0\n",
    "for index, row in df.iterrows():\n",
    "    intra_bool = np.append(intra_bool, round(index)==9)  \n",
    "    if estimate_type == 'mean':\n",
    "        genu_estimate = np.append(genu_estimate, np.mean(df.loc[index]['T1 - genu (WM)']))\n",
    "        genu_std = np.append(genu_std, np.std(df.loc[index]['T1 - genu (WM)']))\n",
    "        splenium_estimate = np.append(splenium_estimate, np.mean(df.loc[index]['T1 - splenium (WM)']))\n",
    "        splenium_std = np.append(splenium_std, np.std(df.loc[index]['T1 - splenium (WM)']))\n",
    "        deepgm_estimate = np.append(deepgm_estimate, np.mean(df.loc[index]['T1 - deep GM']))\n",
    "        deepgm_std = np.append(deepgm_std, np.std(df.loc[index]['T1 - deep GM']))\n",
    "        cgm_estimate = np.append(cgm_estimate, np.mean(df.loc[index]['T1 - cortical GM']))\n",
    "        cgm_std = np.append(cgm_std, np.std(df.loc[index]['T1 - cortical GM']))\n",
    "    elif estimate_type == 'median':\n",
    "        genu_estimate = np.append(genu_estimate, np.median(df.loc[index]['T1 - genu (WM)']))\n",
    "        genu_std = np.append(genu_std, np.std(df.loc[index]['T1 - genu (WM)']))\n",
    "        splenium_estimate = np.append(splenium_estimate, np.median(df.loc[index]['T1 - splenium (WM)']))\n",
    "        splenium_std = np.append(splenium_std, np.std(df.loc[index]['T1 - splenium (WM)']))\n",
    "        deepgm_estimate = np.append(deepgm_estimate, np.median(df.loc[index]['T1 - deep GM']))\n",
    "        deepgm_std = np.append(deepgm_std, np.std(df.loc[index]['T1 - deep GM']))\n",
    "        cgm_estimate = np.append(cgm_estimate, np.median(df.loc[index]['T1 - cortical GM']))\n",
    "        cgm_std = np.append(cgm_std, np.std(df.loc[index]['T1 - cortical GM']))\n",
    "    else:\n",
    "        Exception('Unsupported dataset estimate type.')\n",
    "    ii = ii +1\n",
    "\n",
    "# Store the IDs\n",
    "indexes_numbers = df.index\n",
    "indexes_strings = indexes_numbers.map(str)\n",
    "\n",
    "x1_label='Site #'\n",
    "x2_label='<b>Site #.Meas #</b>'\n",
    "y_label=\"<b>T$_1$ (ms)</b>\"\n",
    "file_prefix = 'WM_and_GM'\n",
    "folder_path=output_folder\n",
    "\n",
    "x1=indexes_numbers\n",
    "x2=indexes_strings\n",
    "y=genu_estimate\n",
    "y_std=genu_std\n",
    "\n",
    "# Paper formatting of x tick labels (remove leading zero, pad zero at the end for multiples of 10)\n",
    "x3=[]\n",
    "for num in x2:\n",
    "    x3.append(num.replace('.0', '.'))\n",
    "\n",
    "index=0\n",
    "for num in x3:\n",
    "    if num[-3] != '.':\n",
    "        x3[index]=num+'0'\n",
    "    index+=1\n",
    "\n",
    "# PYTHON CODE\n",
    "# Module imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.image import imread\n",
    "import scipy.io\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from plotly import __version__\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "config={\n",
    "    'showLink': False,\n",
    "    'displayModeBar': False,\n",
    "    'toImageButtonOptions': {\n",
    "                'format': 'png', # one of png, svg, jpeg, webp\n",
    "                'filename': 'custom_image',\n",
    "                'height': 800,\n",
    "                'width': 960,\n",
    "                'scale': 2 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "            }\n",
    "    }\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import os\n",
    "import markdown\n",
    "import random\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "config={\n",
    "    'showLink': False,\n",
    "    'displayModeBar': False,\n",
    "    'toImageButtonOptions': {\n",
    "                'format': 'png', # one of png, svg, jpeg, webp\n",
    "                'filename': 'custom_image',\n",
    "                'height': 800,\n",
    "                'width': 960,\n",
    "                'scale': 2 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "            }\n",
    "    }\n",
    "\n",
    "\n",
    "dims=genu_estimate.shape\n",
    "fig = make_subplots(rows=4, cols=1, vertical_spacing = 0.07)\n",
    "\n",
    "#data_genu=go.Scatter(\n",
    "#    x=x3,\n",
    "#   y=genu_estimate,\n",
    "#    error_y=dict(\n",
    "#        type='data', # value of error bar given in data coordinates\n",
    "#        array=genu_std,\n",
    "#        visible=True),\n",
    "#    mode = 'markers',\n",
    "#    marker=dict(color='#007ea7'),\n",
    "#    visible = True,\n",
    "#    showlegend = False\n",
    "#\n",
    "#    )\n",
    "\n",
    "\n",
    "# Genu\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgb(252, 141, 98)'\n",
    "    else:\n",
    "        marker_color='rgb(102, 194, 165)'\n",
    "        \n",
    "    data=go.Scatter(\n",
    "        x=[x3[ii]],\n",
    "        y=[genu_estimate[ii]],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[genu_std[ii]],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        data,\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "# Splenium\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgb(252, 141, 98)'\n",
    "    else:\n",
    "        marker_color='rgb(102, 194, 165)'\n",
    "        \n",
    "    data=go.Scatter(\n",
    "        x=[x3[ii]],\n",
    "        y=[splenium_estimate[ii]],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[splenium_std[ii]],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        data,\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# cGM\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgb(252, 141, 98)'\n",
    "    else:\n",
    "        marker_color='rgb(102, 194, 165)'\n",
    "        \n",
    "    data=go.Scatter(\n",
    "        x=[x3[ii]],\n",
    "        y=[cgm_estimate[ii]],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[cgm_std[ii]],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        data,\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# DeepGM\n",
    "for ii in range(dims[0]):\n",
    "    if bool(intra_bool[ii]):\n",
    "        marker_color='rgb(252, 141, 98)'\n",
    "    else:\n",
    "        marker_color='rgb(102, 194, 165)'\n",
    "        \n",
    "    data=go.Scatter(\n",
    "        x=[x3[ii]],\n",
    "        y=[deepgm_estimate[ii]],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=[deepgm_std[ii]],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        marker=dict(\n",
    "            color=marker_color\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        data,\n",
    "        row=4, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    autorange=False,\n",
    "    range=[0,57],\n",
    "    showgrid=False,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickangle = -90,\n",
    "    tickmode='linear',\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=12,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=1, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    title='<b>T<sub>1</sub> (ms)</b>',\n",
    "    autorange=True,\n",
    "    showgrid=True,\n",
    "    dtick=100,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=18,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    autorange=False,\n",
    "    range=[0,57],\n",
    "    showgrid=False,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickangle = -90,\n",
    "    tickmode='linear',\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=12,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=2, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    title='<b>T<sub>1</sub> (ms)</b>',\n",
    "    autorange=True,\n",
    "    showgrid=True,\n",
    "    dtick=100,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=18,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=2, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    autorange=False,\n",
    "    range=[0,57],\n",
    "    showgrid=False,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickangle = -90,\n",
    "    tickmode='linear',\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=12,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=3, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    title='<b>T<sub>1</sub> (ms)</b>',\n",
    "    autorange=True,\n",
    "    showgrid=True,\n",
    "    dtick=250,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=18,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=3, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title='<b>Site #.Meas #</b>',\n",
    "    autorange=False,\n",
    "    range=[0,57],\n",
    "    showgrid=False,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickangle = -90,\n",
    "    tickmode='linear',\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=12,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=4, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    title='<b>T<sub>1</sub> (ms)</b>',\n",
    "    autorange=True,\n",
    "    showgrid=True,\n",
    "    dtick=250,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    tickfont=dict(\n",
    "        family='Times New Roman',\n",
    "        size=18,\n",
    "    ),\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    row=4, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=960,\n",
    "    height=800,\n",
    "    margin=go.layout.Margin(\n",
    "        l=80,\n",
    "        r=40,\n",
    "        b=80,\n",
    "        t=10,\n",
    "    ),\n",
    "    font=dict(\n",
    "        family='Times New Roman',\n",
    "        size=22\n",
    "    ),\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.1,\n",
    "            y=0.85,\n",
    "            showarrow=False,\n",
    "            text='<b>d</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=-0.1,\n",
    "            y=0.55,\n",
    "            showarrow=False,\n",
    "            text='<b>e</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),   \n",
    "        dict(\n",
    "            x=-0.1,\n",
    "            y=0.2,\n",
    "            showarrow=False,\n",
    "            text='<b>f</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),   \n",
    "        dict(\n",
    "            x=-0.1,\n",
    "            y=-0.1,\n",
    "            showarrow=False,\n",
    "            text='<b>g</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),   \n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.986,\n",
    "            showarrow=False,\n",
    "            text='<b>WM - Genu</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.726,\n",
    "            showarrow=False,\n",
    "            text='<b>WM - Splenium</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.425,\n",
    "            showarrow=False,\n",
    "            text='<b>cGM</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),\n",
    "        dict(\n",
    "            x=1,\n",
    "            y=0.143,\n",
    "            showarrow=False,\n",
    "            text='<b>Deep GM</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=20\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "            ),\n",
    "        ],\n",
    "        paper_bgcolor='rgb(255, 255, 255)',\n",
    "        plot_bgcolor='rgb(255, 255, 255)',\n",
    ")\n",
    "\n",
    "#iplot(fig, filename = 'figure6b', config = config)\n",
    "plot(fig, filename = 'figure4d.html', config = config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "report_output",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "display(HTML('figure4a.html'))\n",
    "display(HTML('figure4d.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"caption\">\n",
    "<b>Figure 4</b>  Measured mean T<sub>1</sub> values vs. temperature-corrected NIST reference values of the phantom spheres are presented as linear plots (a), log-log plots (b), and plots of the error relative to the reference T<sub>1</sub> value (c). Green indicates submissions used for inter-submission analyses, and orange indicates the sites used for intra-submission analyses. The dashed lines in plots (c) represent a ±10 % error. Mean T<sub>1</sub> values in two sets of ROIs, white matter (one 5⨯5 voxel ROI for genu, one 5x5 voxel ROI for splenium) and gray matter (three 3⨯3 voxel ROIs for cortex, one 5x5 voxel ROI for deep GM). In subplot g), the missing datapoints for deep GM for sites 1, 8, and 10 were due to the slice positioning of the acquisition not containing deep GM.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 &nbsp; &nbsp; | &nbsp; &nbsp; DISCUSSION\n",
    "\n",
    "This challenge focused on exploring if different research groups could reproduce T<sub>1</sub> maps based on the protocol information reported in a seminal publication {cite:p}`Barral2010-qm`. Eighteen submissions independently implemented the inversion recovery T<sub>1</sub> mapping acquisition protocol as outlined in Barral et al. {cite:p}`Barral2010-qm`, and reported T<sub>1</sub> mapping data in a standard quantitative MRI phantom and/or human brains at 27 MRI sites, using systems from three different vendors (GE, Philips, Siemens). The collaborative effort produced an open-source database of 94 T<sub>1</sub> mapping datasets, including 38 ISMRM/NIST phantom and 56 human brain datasets. The inter-submission variability was twice as high as the intra-submission variability in both phantom and human brain T<sub>1</sub> measurements, **demonstrating that written instructions communicated via a PDF are not enough for reproducibility in quantitative MRI**. This study reports the inherent uncertainty in T<sub>1</sub> measures across independent research groups, which brings us one step closer to producing a practical baseline of variations for this metric.\n",
    "\n",
    "Overall, our approach did show improvement in the reproducibility of T<sub>1</sub> measurements in vivo compared to researchers implementing T<sub>1</sub> mapping protocols completely independently (i.e. with no central guidance), as literature T<sub>1</sub> values in vivo vary more than reported here (e.g., Bojorquez et al. {cite:p}`Bojorquez2017-xh` reports that reported T<sub>1</sub> values in WM vary between 699 to 1735 ms in published literature). We were aware that coordination was essential for a quantitative MRI challenge, which is why the protocol specifications we provided to researchers were more detailed than any guidelines for quantitative MR imaging that were available at the time. Yet, even in combination with the same T<sub>1</sub> mapping processing tools, this level of description (a PDF + post-processing tools) leaves something to be desired. \n",
    "\n",
    "This analysis highlights that more information is needed to unify all the aspects of a pulse sequence across sites, beyond what is routinely reported in a scientific publication. However, in a vendor-specific setting, this is a major challenge given the disparities between proprietary development libraries {cite:p}`Gracien2020-ak`. Vendor-neutral pulse sequence design platforms {cite:p}`Layton2017-dy,Cordes2020-au,Karakuzu2022-af` have emerged as a powerful solution to standardize sequence components at the implementation level (e.g., EF pulse shape, gradients, etc.). Vendor neutrality has been shown to significantly reduce the variability of T<sub>1</sub> maps acquired using VFA across vendors {cite:p}`Karakuzu2022-af`. In the absence of a vendor-neutral framework, a vendor-specific alternative is the implementation of a strategy to control the saturation of MT across TRs {cite:p}`A_G_Teixeira2020-bw`. Nevertheless, this approach can still benefit from a vendor-neutral protocol to enhance accessibility and unify implementations. This is because vendor-specific constraints are recognized to impose limitations on the adaptability of sequences, resulting in significant variability even when implementations are closely aligned within their respective vendor-specific development environments {cite:p}`Lee2019-ei`.\n",
    "\n",
    "The 2020 Reproducibility Challenge, jointly organized by the Reproducible Research and Quantitative MR ISMRM study groups, led to the creation of a large open database of standard quantitative MR phantom and human brain inversion recovery T<sub>1</sub> maps. These maps were measured using independently implemented imaging protocols on MRI scanners from three different manufacturers. All collected data, processing pipeline code, computational environment files, and analysis scripts were shared with the goal of promoting reproducible research practices, and an interactive dashboard was developed to broaden the accessibility and engagement of the resulting datasets (https://rrsg2020.dashboards.neurolibre.org). The differences in stability between independently implemented (inter-submission) and centrally shared (intra-submission) protocols observed both in phantoms and in vivo could help inform future meta-analyses of quantitative MRI metrics {cite:p}`Mancini2020-sv,Lazari2021-oy` and better guide multi-center collaborations.\n",
    "\n",
    "By providing access and analysis tools for this multi-center T<sub>1</sub> mapping dataset, we aim to provide a benchmark for future T<sub>1</sub> mapping approaches. We also hope that this dataset will inspire new acquisition, analysis, and standardization techniques that address non-physiological sources of variability in T<sub>1</sub> mapping. This could lead to more robust and reproducible quantitative MRI and ultimately better patient care.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACKNOWLEDGEMENT\n",
    "\n",
    "<p style=\"text-align:justify;\">\n",
    "The conception of this collaborative reproducibility challenge originated from discussions with experts, including Paul Tofts, Joëlle Barral, and Ilana Leppert, who provided valuable insights. Additionally, Kathryn Keenan, Zydrunas Gimbutas, and Andrew Dienstfrey from NIST provided their code to generate the ROI template for the ISMRM/NIST phantom. Dylan Roskams-Edris and Gabriel Pelletier from the Tanenbaum Open Science Institute (TOSI) offered valuable insights and guidance related to data ethics and data sharing in the context of this international multi-center conference challenge. The 2020 RRSG study group committee members who launched the challenge, Martin Uecker, Florian Knoll, Nikola Stikov, Maria Eugenia Caligiuri, and Daniel Gallichan, as well as the 2020 qMRSG committee members, Kathryn Keenan, Diego Hernando, Xavier Golay, Annie Yuxin Zhang, and Jeff Gunter, also played an essential role in making this challenge possible. We would also like to thank the Canadian Open Neuroscience Platform (CONP), the Quebec Bioimaging Network (QBIN), and the Montreal Heart Institute Foundation for their support in creating the NeuroLibre preprint. Finally, we extend our thanks to all the volunteers and individuals who helped with the scanning at each imaging site.\n",
    "\n",
    "The authors thank the ISMRM Reproducible Research Study Group for conducting a code review of the code (Version 1) supplied in the Data Availability Statement. The scope of the code review covered only the code’s ease of download, quality of documentation, and ability to run, but did not consider scientific accuracy or code efficiency.\n",
    "\n",
    "Lastly, we acknowledge use of ChatGPT (v3), a generative language model, for accelerating manuscript preparation. The co-first authors employed ChatGPT in the initial draft for transforming bullet point sentences into paragraphs, proofreading for typos, and refining the academic tone. ChatGPT served exclusively as a writing aid, and was not used to create or interpret results.\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AVAILABILITY STATEMENT\n",
    "\n",
    "An interactive NeuroLibre preprint of this manuscript is available at https://preprint.neurolibre.org/10.55458/neurolibre.00014/. All imaging data submitted to the challenge, dataset details, registered ROI maps, and processed T<sub>1</sub> maps are hosted on OSF https://osf.io/ywc9g/. The dataset submissions and quality assurance were handled through GitHub issues in this repository https://github.com/rrsg2020/data_submission (commit: 9d7eff1). Note that accepted submissions are closed issues, and that the GitHub branches associated with the issue numbers contain the Dockerfile and Jupyter Notebook scripts that reproduce these preliminary quality assurance results and can be run in a browser using MyBinder. The ROI registration scripts for the phantoms and the T<sub>1</sub> fitting pipeline to process all datasets are hosted in this GitHub repository, https://github.com/rrsg2020/t1_fitting_pipeline (commit: 3497a4e). All the analyses of the datasets were done using Jupyter Notebooks and are available in this repository, https://github.com/rrsg2020/analysis (commit: 8d38644), which also contains a Dockerfile to reproduce the environment using a tool like MyBinder. A dashboard was developed to explore the datasets information and results in a browser, which is accessible here, https://rrsg2020.dashboards.neurolibre.org, and the code is also available on GitHub: https://github.com/rrsg2020/rrsg2020-dashboard (commit: 6ee9321). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[^rrsg2020-challenge]: [ISMRM blog post announcingn the RRRSG challenge](https://blog.ismrm.org/2019/12/12/reproducibility-challenge-2020-join-the-reproducible-research-and-quantitative-mr-study-groups-in-their-efforts-to-standardize-t1-mapping/)\n",
    "\n",
    "[^nist-website]: The [website](https://collaborate.nist.gov/mriphantoms/bin/view/MriPhantoms/SimpleImagingInstructions) provided to the researchers has since been removed from the NIST website.\n",
    "\n",
    "[^phantom-reference]: [Manufacturer's reference for the phantom](https://qmri.com/cmri-product-resources/#premium-system-resources)\n",
    "\n",
    "[^informed-consent]: This [website](https://www.uu.nl/en/research/research-data-management/guides/informed-consent-for-data-sharing) was provided as a resource to the participants for best practices to obtain informed consent for data sharing.\n",
    "\n",
    "[^issue-five]: [rrsg2020/data_submission issue #5](https://github.com/rrsg2020/data_submission/issues/5)\n",
    "\n",
    "[^their-paper]: [http://www-mrsrl.stanford.edu/~jbarral/t1map.html](http://www-mrsrl.stanford.edu/~jbarral/t1map.html)\n",
    "\n",
    "[^residual]: [ https://github.com/qMRLab/qMRLab/blob/master/src/Models_Functions/IRfun/rdNlsPr.m#L118-L129\n",
    "]( https://github.com/qMRLab/qMRLab/blob/master/src/Models_Functions/IRfun/rdNlsPr.m#L118-L129)\n",
    "\n",
    "[^public-repo]: [https://github.com/rrsg2020/analysis](https://github.com/rrsg2020/analysis)\n",
    "\n",
    "[^submission-review]: Submissions were reviewed by MB and AK. Submission guidelines (https://github.com/rrsg2020/data_submission/blob/master/README.md) and a GitHub issue checklist (https://github.com/rrsg2020/data_submission/blob/master/.github/ISSUE_TEMPLATE/data-submission-request.md) were checked. Lastly, the submitted data was passed to the T<sub>1</sub> processing pipeline and verified for quality and expected values. Feedback was sent to the authors if their submission did not adhere to the requested guidelines, or if issues with the submitted datasets were found and if possible, corrected (e.g., scaling issues between inversion time data points).\n",
    "\n",
    "[^three-t]: Strictly speaking, not all manufacturers operate at 3.0 T. Even though this is the field strength advertised by the system manufacturers, there is some deviation in actual field strength between vendors. The actual center frequencies are typically reported in the DICOM files, and these were shared for most datasets and are available in our OSF.io repository (https://osf.io/ywc9g/). From these datasets, the center frequencies imply participants that used GE and Philips scanners were at 3.0T (`~`127.7 MHz), whereas participants that used Siemens scanners were at 2.89T (`~`123.2 MHz). For simplicity, we will always refer to the field strength in this article as 3T.\n",
    "\n",
    "[^my-binder]: https://mybinder.org/v2/gh/rrsg2020/analysis/master?filepath=analysis\n",
    "\n",
    "[^nonlinear]: The T<sub>1</sub> values vs temperature tables reported by the phantom manufacturer did not always exhibit a linear relationship. We explored the use of spline fitting on the original data and quadratic fitting on the log-log representation of the data, Both methods yielded good results, and we opted to use the latter in our analyses. The code is found [here](https://github.com/rrsg2020/analysis/blob/master/src/nist.py), and a Jupyter Notebook used in temperature interpolation development is [here](https://github.com/rrsg2020/analysis/blob/master/temperature_correction.ipynb).\n",
    "\n",
    "[^phantom-version]: Only T<sub>1</sub> maps measured using phantom version 1 were included in this inter-submission COV, as including both sets would have increased the COV due to the differences in reference T<sub>1</sub> values. There were seven research groups that used version 1, and six that used version 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
